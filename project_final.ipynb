{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.impute import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.feature_selection import *\n",
    "\n",
    "import category_encoders as ce\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.txt\", sep = \" \").sort_index()\n",
    "test_df = pd.read_csv(\"testx.txt\", sep = \" \").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Usunięcie pustych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_columns(df):\n",
    "    columns_to_drop =[]\n",
    "    for column in df.columns:\n",
    "        if df[column].isna().all():\n",
    "            columns_to_drop.append(column)\n",
    "    if columns_to_drop:\n",
    "        ret_df = df.drop(columns=columns_to_drop)\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drop_empty_columns(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Zakodowanie kolumn typu str, obj do category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def object_as_category(df):\n",
    "#     new_df = df.copy()\n",
    "#     categorical_columns = new_df.select_dtypes(exclude=[\"number\"]).columns\n",
    "#     try:\n",
    "#         new_df[categorical_columns] = new_df[categorical_columns].fillna(\"NAN\").astype(\"category\")\n",
    "#         return new_df\n",
    "#     except ValueError:\n",
    "#         print(\"No categorical columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = object_as_category(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usunięcie kolumn kategorycznych powtarzających się"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_categories_in_columns(df):\n",
    "    cat_df = df.select_dtypes(exclude=[\"number\"])\n",
    "    num_unique_values_map = defaultdict(list)\n",
    "    for i in range(0, cat_df.shape[1]):\n",
    "        column = cat_df.iloc[:, i]\n",
    "        num_unique = column.nunique(dropna=False)\n",
    "        num_unique_values_map[num_unique].append(column.name)\n",
    "    return num_unique_values_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {2: ['Var191', 'Var211', 'Var213', 'Var215', 'Var224'],\n",
       "             352: ['Var192'],\n",
       "             51: ['Var193'],\n",
       "             4: ['Var194', 'Var205', 'Var225'],\n",
       "             23: ['Var195', 'Var219', 'Var226'],\n",
       "             3: ['Var196', 'Var201', 'Var208', 'Var218'],\n",
       "             214: ['Var197'],\n",
       "             3876: ['Var198', 'Var220', 'Var222'],\n",
       "             4384: ['Var199'],\n",
       "             13331: ['Var200', 'Var214'],\n",
       "             5553: ['Var202'],\n",
       "             6: ['Var203', 'Var210'],\n",
       "             100: ['Var204'],\n",
       "             22: ['Var206'],\n",
       "             14: ['Var207'],\n",
       "             80: ['Var212'],\n",
       "             1834: ['Var216'],\n",
       "             12495: ['Var217'],\n",
       "             7: ['Var221', 'Var227'],\n",
       "             5: ['Var223', 'Var229'],\n",
       "             30: ['Var228']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unique_values_map = count_categories_in_columns(train_df)\n",
    "num_unique_values_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_repeated_cat_columns(df, num_unique_values_map):\n",
    "    columns_to_drop = set()\n",
    "    for key, value in num_unique_values_map.items():\n",
    "        len_col_list = len(value)\n",
    "        if len_col_list > 1:\n",
    "            for i in range(len_col_list):\n",
    "                col_name_i = value[i]\n",
    "                for j in range(i+1, len_col_list):\n",
    "                    col_name_j = value[j]\n",
    "                    lab_encoder = ce.OrdinalEncoder()\n",
    "                    transformed = lab_encoder.fit_transform(df[[col_name_i, col_name_j]])\n",
    "                    if accuracy_score(transformed.iloc[:, 0], transformed.iloc[:, 1]) > 0.99:\n",
    "                        columns_to_drop.add(col_name_i)\n",
    "                        #print(\"Break\" ,key,  i, j, accuracy_score(transformed.iloc[:, 0], transformed.iloc[:, 1]))\n",
    "                        break\n",
    "    return df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drop_repeated_cat_columns(train_df, num_unique_values_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Problem niewystępujących kategorii w zbiorze treningowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {2: ['Var191', 'Var211', 'Var213', 'Var215', 'Var224'],\n",
       "             362: ['Var192'],\n",
       "             51: ['Var193'],\n",
       "             4: ['Var194', 'Var196', 'Var205', 'Var225'],\n",
       "             23: ['Var195', 'Var219', 'Var226'],\n",
       "             226: ['Var197'],\n",
       "             5074: ['Var199'],\n",
       "             3: ['Var201', 'Var208', 'Var218'],\n",
       "             5714: ['Var202'],\n",
       "             6: ['Var203', 'Var210'],\n",
       "             100: ['Var204'],\n",
       "             22: ['Var206'],\n",
       "             14: ['Var207'],\n",
       "             81: ['Var212'],\n",
       "             15416: ['Var214'],\n",
       "             2016: ['Var216'],\n",
       "             13991: ['Var217'],\n",
       "             7: ['Var221', 'Var227'],\n",
       "             4291: ['Var222'],\n",
       "             5: ['Var223', 'Var229'],\n",
       "             30: ['Var228'],\n",
       "             2049: ['Var198', 'Var220'],\n",
       "             4322: ['Var200']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_train = train_df.iloc[:,:-1]\n",
    "joined_df = pd.concat([mod_train, test_df], sort=False).sort_index()\n",
    "count_categories_in_columns(joined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6. Funkcja licząca liczbę kategorii o konkretnej liczbie wystąpień"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_categories_by_size(df):\n",
    "    columns_dict = {}\n",
    "    cat_columns = df.select_dtypes(exclude=[\"number\"]).columns\n",
    "    for column in cat_columns:\n",
    "        columns_dict[column] = train_df[column].value_counts(dropna=False).to_frame().groupby(column).size()\n",
    "    return columns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dict_categories_by_size = count_categories_by_size(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Funkcja określająca frakcję jedynek i liczność w danej kategorii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ones_fraction_and_size_in_category(df):\n",
    "    columns_dict = {}\n",
    "    cat_columns = df.select_dtypes(exclude=[\"number\"]).columns\n",
    "    for column in cat_columns:\n",
    "        ones_fraction = df[[column, \"class\"]].fillna(-1).groupby(column)[\"class\"].mean()\n",
    "        cat_size = df[[column]].fillna(-1).groupby(column).size()\n",
    "        columns_dict[column] = pd.DataFrame(data={\"ones_fraction\": ones_fraction, \"cat_size\": cat_size})\n",
    "    return columns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dict_categories_description = count_ones_fraction_and_size_in_category(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ones_fraction</th>\n",
       "      <th>cat_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var197</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0.025424</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0LaQ</th>\n",
       "      <td>0.068627</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0WHw</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0Xwj</th>\n",
       "      <td>0.076087</td>\n",
       "      <td>3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0Y9G</th>\n",
       "      <td>0.083582</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ones_fraction  cat_size\n",
       "Var197                         \n",
       "-1           0.025424       118\n",
       "0LaQ         0.068627       102\n",
       "0WHw         0.111111       180\n",
       "0Xwj         0.076087      3680\n",
       "0Y9G         0.083582       335"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dict_categories_description[\"Var197\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Zdropowanie kolumn z kategoriami o liczności więcej niż "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_above_n_categories(df, n):\n",
    "    columns_to_drop = set()\n",
    "    cat_columns = df.select_dtypes(exclude=[\"number\"]).columns\n",
    "    for column in cat_columns:\n",
    "        if train_df[column].nunique(dropna=False) > n:\n",
    "            columns_to_drop.add(column)\n",
    "    return df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drop_columns_above_n_categories(train_df, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Wypełnienie pustych zmiennych numerycznych i dodanie kolumn informujących o NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_in_numerical_add_column(df):\n",
    "    new_df = df.copy()\n",
    "    numerical_columns = new_df.select_dtypes(include=[\"number\"]).columns\n",
    "    for column in numerical_columns:\n",
    "        if new_df[column].isna().any():\n",
    "            new_df[column+\"_isfilled\"] = new_df[column].isna().map({True:1, False:0})\n",
    "        new_df[column] = new_df[column].fillna(new_df[column].median())\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = fill_na_in_numerical_add_column(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 373)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import lightgbm\n",
    "import catboost\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    return acc, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = list(train_df.select_dtypes(exclude=[\"number\"]).columns)\n",
    "for column in cat_columns:\n",
    "    train_df[column] = train_df[column].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_encoder = ce.BinaryEncoder()\n",
    "#label_encoder = ce.OrdinalEncoder()\n",
    "X = train_df.loc[:, train_df.columns != \"class\"]\n",
    "y = train_df[\"class\"]\n",
    "#label_encoder.fit(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = label_encoder.transform(X_train)\n",
    "X_test = label_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgboost.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000)\n",
    "eval_set = [(X_test, y_test)]\n",
    "xgb_model.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9518939393939394, 0.447070914696814, 0.8176691729323309)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_scores(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"max_depth\": [-1, 100],\n",
    "              \"learning_rate\" : [0.04, 0.05, 0.06],\n",
    "              \"num_leaves\": [35, 50],\n",
    "              \"n_estimators\": [1000],\n",
    "              \"max_bin\": [100, 150],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_model = lightgbm.LGBMClassifier(scale_pos_weight = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.04, 'max_bin': 100, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.951590909090909, 0.460431654676259, 0.797153024911032)\n",
      "{'learning_rate': 0.04, 'max_bin': 100, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9511363636363637, 0.4573484069886948, 0.791814946619217)\n",
      "{'learning_rate': 0.04, 'max_bin': 100, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.951590909090909, 0.460431654676259, 0.797153024911032)\n",
      "{'learning_rate': 0.04, 'max_bin': 100, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9511363636363637, 0.4573484069886948, 0.791814946619217)\n",
      "{'learning_rate': 0.04, 'max_bin': 150, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9513636363636364, 0.4614594039054471, 0.7918871252204586)\n",
      "{'learning_rate': 0.04, 'max_bin': 150, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9509090909090909, 0.4614594039054471, 0.7835951134380453)\n",
      "{'learning_rate': 0.04, 'max_bin': 150, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9513636363636364, 0.4614594039054471, 0.7918871252204586)\n",
      "{'learning_rate': 0.04, 'max_bin': 150, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9509090909090909, 0.4614594039054471, 0.7835951134380453)\n",
      "{'learning_rate': 0.05, 'max_bin': 100, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9514393939393939, 0.4614594039054471, 0.7932862190812721)\n",
      "{'learning_rate': 0.05, 'max_bin': 100, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9517424242424243, 0.460431654676259, 0.8)\n",
      "{'learning_rate': 0.05, 'max_bin': 100, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9514393939393939, 0.4614594039054471, 0.7932862190812721)\n",
      "{'learning_rate': 0.05, 'max_bin': 100, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9517424242424243, 0.460431654676259, 0.8)\n",
      "{'learning_rate': 0.05, 'max_bin': 150, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9505303030303031, 0.460431654676259, 0.7777777777777778)\n",
      "{'learning_rate': 0.05, 'max_bin': 150, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9512121212121212, 0.4573484069886948, 0.7932263814616756)\n",
      "{'learning_rate': 0.05, 'max_bin': 150, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9505303030303031, 0.460431654676259, 0.7777777777777778)\n",
      "{'learning_rate': 0.05, 'max_bin': 150, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9512121212121212, 0.4573484069886948, 0.7932263814616756)\n",
      "{'learning_rate': 0.06, 'max_bin': 100, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9512121212121212, 0.460431654676259, 0.7901234567901234)\n",
      "{'learning_rate': 0.06, 'max_bin': 100, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9506818181818182, 0.4573484069886948, 0.7834507042253521)\n",
      "{'learning_rate': 0.06, 'max_bin': 100, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9512121212121212, 0.460431654676259, 0.7901234567901234)\n",
      "{'learning_rate': 0.06, 'max_bin': 100, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9506818181818182, 0.4573484069886948, 0.7834507042253521)\n",
      "{'learning_rate': 0.06, 'max_bin': 150, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9506060606060606, 0.45940390544707094, 0.7801047120418848)\n",
      "{'learning_rate': 0.06, 'max_bin': 150, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9512121212121212, 0.460431654676259, 0.7901234567901234)\n",
      "{'learning_rate': 0.06, 'max_bin': 150, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 35}\n",
      "(0.9506060606060606, 0.45940390544707094, 0.7801047120418848)\n",
      "{'learning_rate': 0.06, 'max_bin': 150, 'max_depth': 100, 'n_estimators': 1000, 'num_leaves': 50}\n",
      "(0.9512121212121212, 0.460431654676259, 0.7901234567901234)\n"
     ]
    }
   ],
   "source": [
    "for param in ParameterGrid(param_dist):\n",
    "    lightgbm_model = lightgbm.LGBMClassifier(scale_pos_weight = 2, **param)\n",
    "    eval_set = [(X_test, y_test)]\n",
    "    lightgbm_model.fit(X_train, y_train, early_stopping_rounds=100, eval_set=eval_set, eval_metric=\"logloss\", verbose=False, \n",
    "                   categorical_feature=list(cat_columns))\n",
    "    y_pred_lightgbm = lightgbm_model.predict(X_test)\n",
    "    print(param)\n",
    "    print(calculate_scores(y_test, y_pred_lightgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  72 | elapsed: 13.7min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 14.9min finished\n",
      "c:\\program files\\python37\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Var191', 'Var193', 'Var194', 'Var195', 'Var196', 'Var201', 'Var203', 'Var204', 'Var205', 'Var206', 'Var207', 'Var208', 'Var210', 'Var211', 'Var212', 'Var213', 'Var215', 'Var218', 'Var219', 'Var221', 'Var223', 'Var224', 'Var225', 'Var226', 'Var227', 'Var228', 'Var229']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.04, max_bin=100,\n",
       "        max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "        min_split_gain=0.0, n_estimators=1000, n_jobs=-1, num_leaves=35,\n",
       "        objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "        scale_pos_weight=2, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(lightgbm_model, n_jobs=-1, param_grid=param_dist, cv = 3, scoring=\"roc_auc\", verbose=10)\n",
    "grid_search.fit(X, y, categorical_feature=cat_columns)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.04, max_bin=100,\n",
       "        max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "        min_split_gain=0.0, n_estimators=1000, n_jobs=-1, num_leaves=35,\n",
       "        objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "        scale_pos_weight=2, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = grid_search.best_estimator_\n",
    "lgb_model.fit(X_train, y_train, categorical_feature=cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lightgbm = lgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9507575757575758, 0.44295991778006166, 0.7996289424860853)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_scores(y_test, y_pred_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_lightgbm = lightgbm_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9780597014925373, 0.7431052093973443, 0.9448051948051948)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_scores(y_train, y_pred_train_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = catboost.CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1f5860bd4e0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.fit(X_train, y_train, verbose=False, cat_features=list(cat_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9521969696969697, 0.44809866392600206, 0.8226415094339623)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cat = cat_model.predict(X_test)\n",
    "calculate_scores(y_test, y_pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
